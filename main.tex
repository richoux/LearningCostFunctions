\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai20.sty is NOT the same than previous years'
\usepackage{ijcai20}

\usepackage[english]{babel}
\usepackage[T1]{fontenc}

% Use the postscript times font!
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algorithmic}
\urlstyle{same}

\usepackage{xspace}
\usepackage[dvipsnames, table]{xcolor}
\usepackage{color}
\usepackage{amsfonts}
\usepackage{adjustbox}
%\usepackage[ruled,linesnumbered]{algorithm2e}
\usepackage{hyperref}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = blue %Colour of citations
}

%\title{Automatic Cost Function Generation ('learning' in the title?)}
\title{Automatic Learning of Cost Functions to Help Modeling Cost Function Networks}

\iffalse
\author{
Florian Richoux$^{1,2}$
\and
Jean-François Baffier$^3$
\affiliations
$^1$JFLI, CNRS, NII\\
$^2$Université de Nantes\\
$^3$RIKEN AIP
\emails
florian.richoux@polytechnique.edu,
jf@baffier.fr
}
\fi

\newcommand{\ie}{\textit{i.e.}}
\newcommand{\cp}{\textsc{CP}\xspace}
\newcommand{\csp}{\textsc{CSP}\xspace}
\newcommand{\cop}{\textsc{COP}\xspace}
\newcommand{\cfn}{\textsc{CFN}\xspace}
\newcommand{\cf}{\textsc{cf}\xspace}
\newcommand{\wcsp}{\textsc{WCSP}\xspace}
\newcommand{\ghost}{\textsc{GHOST}\xspace}

\newcommand{\flo}{\textcolor{blue}{\bf Flo}\xspace}
\newcommand{\jf}{\textcolor{red}{\bf JF}\xspace}

\begin{document}

\maketitle

\begin{abstract}
  Cost  Function  Networks  (\cfn)   are  a  formalism  in  Constraint
  Programming  to  model  combinatorial satisfaction  or  optimization
  problems.   By associating  a function  to each  constraint type  to
  evaluate the quality  of an assignment, it  extends the expressivity
  of regular \csp/\cop formalisms but at  a price of making harder the
  problem    modeling.     Indeed,     in    addition    to    regular
  variables/domains/constraints sets,  one must provide a  set of cost
  functions (\cf) that are not always easy to define.  Here we propose
  a  method to  automatically learn  a \cf  of a  constraint, given  a
  function deciding if  assignments are valid or not.  This  is to the
  best  of our  knowledge  the first  attempt  to automatically  learn
  $\cf$s.  Our  method aims to  learn $\cf$s in a  supervised fashion,
  trying to  reproduce the Hamming  distance, by using a  variation of
  neural  networks  allowing us  to  get  explainable results,  unlike
  regular artificial neural networks.  We experiment it on 5 different
  constraints  to   show  its  versatility.   Experiments   show  that
  functions  learned on  small  dimensions scale  on high  dimensions,
  outputting a  perfect or near-perfect Hamming  distance.  Our method
  can be  used to  automatically generate $\cf$s  and then  having the
  expressivity  of  \cfn  with  the  same  modeling  effort  than  for
  \csp/\cop.
\end{abstract}

\section{Introduction}\label{sec:introduction}

TODO: CP  est difficile à  modéliser~\cite{Puget2004,Wallace2003}, CFN
ajoute une structure  utile au solveur mais est  également difficile à
modéliser  (même plus)  : générer  automatiquement les  CF pour  aider
l'utilisateur à modéliser son problème.  Pour palier à la modélisation
CP, on se repose sur  l'utilisation de méta-heuristiques qui n'ont pas
besoin       d'une        sélection       fine        des       bonnes
contraintes. \cite{AMJFH2011,Bessiere2015,CBLS}

Motivation : pas forcément facile ni intuitif de trouver une bonne CF.


\subsection{Of the interest of \cfn over classic CSP}
As shown in  [previous studies], using a cost function to guide a CSP solver, even for a satisfaction problem, generally significantly improve the convergence speed to a solution.  It is important to note that using a \cfn with manual input of  the cost functions (that  is the current
general usage of such solvers) significantly increases the difficulty for the user.

This research aims to provide a set of tools to compute or estimate those cost functions in a  way that provides the user with the following guarantees: CSP $<$ CFN-auto $\leq$ CFN-manual.

We hope to provide methods that can lead to "CFN-manual $\leq$ CFN-auto"  eventually for some (if not most) families of constraints.

\section{Preliminaries}\label{sec:preliminaries}
Topo sur CPPN \jf \cite{CPPN}.

In the  literature, Cost  Function Networks  (\cfn) and  Weighted \csp (\wcsp)  are  synonyms~\cite{Zytnicki2009,Bessiere2011}.  Some papers like~\cite{Allouche2012} present  \cfn to be the formalism and \wcsp the problem of finding an assignment minimizing the combined cost function of a given \cfn instance. Since it is rarely a good thing in Science to have two different names for the same notion, we start this paper by proposing clear, distinct definitions of \cfn and \wcsp.

\subsection{Definitions of \wcsp and \cfn} 

We propose to keep the definition of a \wcsp from the literature: a \textbf{\wcsp} is a tuple ($V$,$D$,$C$,$F$) where $V$ is a finite set of variables, $D$ a finite set of domains, one for each variable in $V$, each domain being the set of values a variable can take, $C$ a finite set of constraints over variables in $V$, determining which combinations of values in $D$ are allowed or forbidden to describe our problem, and finally a finite set $F$ composed of cost functions, one for each constraint in $C$. Let us denote by $D_c$ the Cartesian product of the domain of variables involved in a constraint $c \in C$. The cost function $f_c \in F$ associated to the constraint $c$ is a function $f_c: D_c \rightarrow \{0,k\}$ where $k \in \mathbb{N} \cup \{\infty\}$ is the special cost for assignments violating the constraint $c$. Thus, an assignment $\alpha$ satisfies the constraint $c$ iff $f_c(\alpha) < k$ holds. The function $f_c$ allows us to rank assignments and to express softness within the constraint~$c$.

A \textbf{\cfn} is also defined by a tuple ($V$,$D$,$C$,$F$) with the same sets as \wcsp. The difference we propose lies in the interpretation of cost functions $f_c$. In this paper, cost functions defined in a \cfn are functions $f_c: D_c \rightarrow \mathbb{R}^+$. An assignment $\alpha$ satisfies the constraint $c$ iff $f_c(\alpha) = 0$ holds. All other strictly positive outputs of $f_c$ lead to forbidden assignments. Therefore, \cfn is considering hard (or crisp) constraints only, unlike \wcsp. Strictly positive outputs of $f_c$ are then interpreted like preferences over invalid assignments: the closer $f_c(\alpha)$ is to 0, the closer $\alpha$ is to be a valid assignment.

In the same way, a \csp instance is a network of constraints, \ie, a network of predicates expressing if an assignment satisfies or not each constraint, a \cfn instance is a network of functions expressing if an assignment satisfies the constraints or how close it is to satisfy them. Thus, this formalism \cfn allows us to express a finer structure about the problem, since we furnish with cost functions an ordered structure over invalid assignments, a solver can exploit efficiently to improve the search. We illustrate this in Section~\ref{sec:xp}.

Observe we can also deal with optimization problems with a \cfn by adding to the tuple ($V$,$D$,$C$,$F$) an objective function to optimize.

% \wcsp and \cfn are defined by close but different flavors throughout
% the litterature. To make the most  of both, we chose to consider the
% following definitions for those two concepts.

%  \paragraph{\wcsp}   is  considering   soft  constraints,   where  a
% constraint is unsatisfyed iif its associated cost function outputs a
% value below a given threshold $k$ (can be infinite).

%  \paragraph{\cfn}  is  considering   hard  constraints  only.   Like
% constraint  networks helping solvers  to find solutions by  giving a
% structure of  the problem, CFN gives, in addition  of the constraint
%  network,  a structure  on  configurations  to  help the  solver  to
% determine if an unsatisfying configuration  is near to be a solution
% or not.

From those  definition, we  can consider \wcsp  and the  \cfn variants
(satisfaction  and  optimization)  to have  different  expressiveness:
\cfn-sat $<$ \wcsp $<$ \cfn-opt

In  this study,  we deliberately  chose  to focus  on \cfn  as we  can
naturally transform any \wcsp into \cfn-opt.

\section{Method design \jf}\label{sec:method}
\flo{Préciser ce qu'est notre la loss function}

From  head to  toes,  how our  framework  is designed  (interpolation,
pre-processing and such) to fit a solver (here GHOST).

Modèles (qui n'ont pas marché) :
\begin{itemize}
\item CF comme combinaison linéaire de sinus
\item CF en CPPN de fonctions simples (sinus, tanh, sigmoid, ...)
\item CF apprise par CFN (lol) avec smoothness comme fonction objectif.
\item Relaxation du SL en regardant seulement l'ordre  de Hamming  avec
le modèle CPPN.
\end{itemize}

\flo: insister  sur le  fait que, malgrè  le fait  que l'apprentissage
supervisé   se   fasse   à   proprement   parler   sur   des   données
``configurations + coût de Hamming''  (réel ou estimé), un utilisateur
ne  fournit QUE  le concept  de la  contrainte visée,  et non  pas ces
données en  question.  Nous fournissons  les outils pour  produire les
données ``configurations + coût de Hamming'' à partir d'un concept, et
cette   production   peut   être   automatisée   dans   la   procédure
d'apprentissage, et est donc transparente à l'utilisateur.

\subsection{Scaling Issues}\label{subsec:issues}
Scaling our  results on small instances is challenging.  In this subsection, we cover four possible approaches that are either unsuccessful or not yet efficient.

\paragraph{Learning a cost function on small space}
For general constraints, there is no generic idea to extend a known cost function from a small space to a higher dimension one.

\section{Experiments}\label{sec:xp}
To show the versatility of our method, we tested it on five very different constraints:  AllDifferent, Ordered,  LinearSum, NoOverlap1D, and Minimum.   According to XCSP specifications~\cite{xcsp}  (see also \href{http://xcsp.org/specifications}{xcsp.org/specifications}), those global  constraints   below  to  four different   families:  Comparison (AllDifferent    and     Ordered),    Counting/Summing    (LinearSum), Packing/Scheduling  (NoOverlap1D)  and Connection  (Minimum).   Always according to XCSP specifications, these five constraints are among the twenty most popular and common constraints.  We give a  brief description of those five constraints below:

\paragraph{AllDifferent} ensures that variables must all be assigned to different values.

\paragraph{Ordered} ensures  that an  assignment of variables  must be ordered, given a total order. In this paper, we choose the total order $\leq$. Thus, for all indexes $i,j \in \{1,n\}$ with $n$ the number of variables, $i < j$ implies $x_i \leq x_j$.

\paragraph{LinearSum}       ensures       that      the       equation $x_1 + x_2 +  \ldots + x_n = p$ holds, with the  parameter $p$ a given integer.

\paragraph{NoOverlap1D}  is considering  variables as  tasks, starting from a  certain time (their  value) and each  with a given  length $p$ (their  parameter).    The  constraint  ensures  that   no  tasks  are overlapping,  \ie, for  all indexes  $i,j  \in \{1,n\}$  with $n$  the number   of   variables,  we   have   $x_i   +   p_i  \leq   x_j$   or $x_j + p_j \leq  x_i$.  To have a simpler code,  we have considered in this paper that all tasks have the same length $p$.

\paragraph{Minimum} ensures that the minimum value of an assignment verifies a given numerical condition.  In this paper, we choose to consider that the minimum value must be greater than or equals to a given parameter $p$.

\subsection{Experimental protocols}

To have experimental evidence of the efficiency of our method, we conducted several different experiments.

All experiments have been conducted on a computer with a CPU Core i7 6700K and  48GB of RAM,  running on  Ubuntu 18.04. Programs have been compiled with GCC with the 03 optimization option.

\subsubsection{Experiment 1: scaling}

The first one consists in learning cost functions on a tiny, complete  constraint space  (\flo:  on doit  définir  ce  qu'est  cet espace), composed of about 500  configurations (\flo: être  clair sur les définitions de configuration et solution).  It is then possible to compute the  Hamming distance between each configuration with its closest solution,  \ie, the solution that requires to modify the smallest number of variables from the considered configuration. The goal of this experiment is to show that learned cost functions scale to high-dimensional constraints,  making sufficient the use of our method on small constraint instances to get efficient cost functions on any number of variables.

We run  100 cost function learnings on the same complete constraint space, for each of the five constraints presented above  (\flo: écrire dans  la section  3 que  la loss  est la  différence entre  le Hamming estimé et le Hamming réel). We then analyze the frequency of cost functions we get and compute the discrepancies of the most frequent ones to the Hamming distance, over  100 sampled configurations composed of  100  variables on domains of size  100, belonging to constraint  spaces of size  $10^{200}$  (compare to constraint spaces of size around 500 used to learn cost functions).

\flo: Apprendre une CF sur une petit instance, et la comparer avec 1. les métriques  sur cette  même instance,  2.  les métriques  sur une  plus grande instance et 3. Une CF apprise sur une plus grande instance.

\subsubsection{Experiment 2: learning over incomplete spaces}

If for any reasons, it is not possible to build a complete constraint space, a robust system must be able to learn effective cost functions on large,  incomplete spaces where the exact Hamming cost  (\flo: Hamming cost of config $c$ =  Hamming distance of $c$ with its closest solution) of their configurations is unknown.

In this experiment,  we sample $k$ solutions and  $k$ non-solutions on large constraint spaces,  approximate the  Hamming cost of each non-solution by computing their  Hamming distance with the closest solution among the $k$ ones, and learn cost functions on these $2k$ configurations and their estimated Hamming cost. Then, we compare the frequency of cost functions we obtain this way with the frequency of cost functions learned on small and complete constraint spaces, as well as the discrepancies of the most common cost functions obtained both ways to the real Hamming distance. \flo: pas super clair ; faire un  effort pour  mieux  présenter  la métrique  de  réussite de  cette expérimentation. 

\flo:  Comparaison  des  CF  obtenues avec  différent  pourcentage  de
l'espace des configurations samplée.

\flo: Généralisation  : apprendre  une CF  pour une  instance avec  certains
paramètres  et  tester sur  d'autres  paramètres  (et/ou sur  d'autres
tailles aussi)

\subsubsection{Experiment 3: using learned $\cf$s to solve problems}

Here, we use learned cost functions for AllDifferent and LinearSum in \cfn modeling  3 problems:  Sudoku (using AllDifferent),  Magic Square (using  LinearSum), and Killer  Sudoku  (using both AllDifferent and LinearSum). We use a local search solver to solve these problems and consider the mean run-time as a metric to compare pure \csp models (so without cost functions),  \cfn models with learned cost functions, and \cfn models with handmade cost functions.

\paragraph{Sudoku} is a puzzle game presented like a $9 \times 9$ grid where each cell of the grid must be filled up with a number from 1 to 9,  such that each row and each column contains precisely once each number. In addition, the grid is composed of 9 smaller squares of size $3  \times 3$  which must also be filled with each number exactly once. In other words, all numbers of each row, column, and square must be different,   which is correctly modeled by the  AllDifferent constraint.   Usually, the grid is pre-filled with a few numbers, preventing from finding a trivial solution.  In this paper,  to have randomly generated Sudoku instances, we have pre-filled the entire grid randomly with the expected total number of 1s, 2s, etc., and ask the solver to find a  permutation satisfying all  AllDifferent constraints described above.

\paragraph{Magic Square} is a $n \times n$ grid that must be filled up with all number from 1 to $n^2$ (thus, all numbers must appear exactly once in the grid), such that the sum of each row, each column, and the two diagonals must be equal to a constant $c$.  We can avoid using the AllDifferent constraint by randomly filling up the grid with all expected numbers and ask the solver to find a correct permutation. The constraints over the rows, columns, and the two diagonal are modeled with LinearSum since the value of  $c$ only depends on $n$  and is known to be $c = n(n^2 + 1)/2$.

\paragraph{Killer Sudoku}  is the same as Sudoku but in such a way that the grid is paved with blocks of cells, named cages, usually composed of 2, 3, or 4 cells.  Each cage is associated an integer, and the sum  of numbers in their cells must be equals to their integer. A  killer Sudoku instance starts with an empty grid, cages preventing from trivial solutions. AllDifferent constraints are used to model the regular Sudoku rules of this puzzle game, and LinearSum constraints are modeling cages.

\flo: Comparaison des  CF obtenues sur des  benchs avec des CF  handmades et
sans CF

\subsection{Results}
Figure et tableaux \jf.

In this part, we denote by $n$ the number of variables, $d$ the domain size, and $p$  the value of an eventual parameter. Constraint instances are denoted by \textit{name-n-d[-p]}.

\subsubsection{Experiment 1}

% Since many different cost functions can be learn over 100 runs for the
% same constraint instance, we will only consider cost functions learned
% at least 10\% of the time.

As written in  Section~\ref{sec:method}, our loss function is the absolute value of the difference between the expected Hamming cost of a  configuration $c$  and the  Hamming cost estimated for the cost function on $c$. The loss function is then normalized with the size of the constraint space used for training, giving us the training error of the constraint space, \ie,  the average difference between expected and estimated  Hamming costs.   Thus,  a  cost function $f$  with a training error of 2  means that  $f$ estimations on configurations used for training are on average +2 or -2 from the real Hamming cost.

% In  this experiment,  we  learn 100  times a  cost  function for  each
% constraint instance, and  we compute the mean of  their training error
% over  the  whole  configuration  space.  The  training  error  is  the
% difference between the expected Hamming cost and the estimated Hamming
% cost over a  configuration from the configuration space  used to train
% the  function.  For instance,  if  a  cost  function  outputs 5  on  a
% configuration $c$  when the expected  Hamming cost  of $c$ is  3, this
% function has an error of 2. 

In  this experiment,  we  learn 100  times a  cost  function for  each
constraint instance. Table\ref{tab:cf_small} shows for each constraint
instance the median  and mean training errors of the  100 learned cost
functions,  as well  as  the  training error  of  the most  frequently
learned  cost function,  and  its frequency  in  parenthesis. In  this
experience,   the   most   frequently  learned   cost   function   was
systematically the one with the lowest training error.

Notice that  the most  frequent cost function  for all\_different-4-5,
learned 97 over  100 runs, is actually two  equivalent functions $f_1$
and $f_2$ expressed differently, respectively learned 58 and 39 times.
For a configuration $c = (c_1, c_2, \ldots, c_n)$, $f_1$ and $f_2$ are
defined as follows:
\begin{align*}
  f_1(c) &:= Count_{\geq 0}( Number\ of\ c_j\ s.t.\ i<j\ and\ c_i=c_j)\\
  and&\\
  f_2(c) &:= Count_{\geq 0}( Number\ of\ c_j\ s.t.\ i>j\ and\ c_i=c_j)
\end{align*}

Due to space limitations, other learned cost functions are not detailed in this paper.   We invite the reader to look  at them in the code                           repository                           at \href{https://anonymous.4open.science/r/50ffb3e8-8918-4f59-9b8d-ef80060585ef/}{anonymous.4open.science/r/50ffb3e8-8918-4f59-9b8d-ef80060585ef} by following the procedure described in the README file.

% \paragraph{all\_different-4-5} Two cost functions were 

% \paragraph{ordered-4-5} 

% \paragraph{linear\_sum-3-8-12}

% \paragraph{no\_overlap-3-8-2}

% \paragraph{minimum-4-5-3}

\begin{table}
  \centering
\begin{tabular}{|l|l|l|l|}
  \hline
  Constraints & median & mean & most freq.\\
  \hline
  all\_different-4-5 & 0 & 0.03 & 0~~~~~~(97)\\
  ordered-4-5 & 0.08 & 0.08 & 0.08~(100)\\
  linear\_sum-3-8-12 & 0.01 & 0.05 & 0.01~(74)\\
  no\_overlap-3-8-2 & 0.14 & 0.19 & 0.11~(50)\\
  minimum-4-5-3 & 0 & 0.04 & 0~~~~~~(88)\\
  \hline
\end{tabular}
\caption{Median, mean and  most frequent training error  over 100 runs
  (with frequency in parenthesis) of learned cost functions over small
  complete constraint spaces.}
\label{tab:cf_small}
\end{table}

<<<<<<< HEAD
Learning cost functions over small complete constraint spaces of about
500 configurations takes about 10 seconds on our hardware.

Table~\ref{tab:cf_small} shows very good performances, but it might be
due  to overfitting  on those  small constraint  spaces.  To  check if
learned  cost functions  do not  overfit and  can scale  to constraint
instances on higher dimensions, we use the most frequent cost function
learned on each  constraint for estimating the Hamming  cost of 20,000
random configurations sampled from high-dimensional constraint spaces.

For AllDifferent, LinearSum and Minimum, it  is easy to define by hand
a function computing the Hamming cost of any configuration $c$ without
generating  the  whole constraint  space.  For  these constraints,  we
tested the  corresponding cost function  on spaces with  100 variables
and domains of size 100.

For  Ordered   and  NoOverlap1D,  since  these   two  constraints  are
intrinsically  combinatoric, finding  a function  computing the  exact
Hamming cost  of any configuration  is not trivial.   Therefore, using
Latin hypercube sampling  to have a good  diversity of configurations,
we  sampled 10,000  solutions and  10,000 non-solutions  in constraint
spaces  of  ordered-12-18  (so $18^{12}$  configurations,  \ie,  about
$1.15\times         10^{15}$)          and         no\_overlap-10-35-3
($35^{10}  \simeq   2.75\times  10^{15}$  configurations).    Then  we
approximate  the Hamming  cost of  each non-solution,  considering the
closest solution among the 10,000 sampled solutions.
=======
Learning cost functions over small complete constraint spaces of about 500 configurations takes about 10 seconds on our hardware.

Table~\ref{tab:cf_small} shows excellent performances, but it might be due to overfitting on those small constraint spaces.  To check if learned cost functions do not overfit and can scale to constraint instances on higher dimensions, we use the most frequent cost function learned on each constraint for estimating the Hamming cost of 20,000 random configurations sampled from high-dimensional constraint spaces.

For AllDifferent, LinearSum and Minimum, it is easy to define by hand a function computing the Hamming cost of any configuration $c$ without generating the whole constraint space.  For these constraints,  we tested the corresponding cost function on spaces with  100 variables and domains of size 100.

For  Ordered and  NoOverlap1D,  since these two constraints are intrinsically combinatoric, finding a function computing the exact Hamming cost of any configuration is not trivial.  Therefore,  we sampled 10,000 solutions and 10,000 non-solutions in constraint spaces of   ordered-12-18   (so    $18^{12}$   configurations,   \ie,   about $1.15\times         10^{15}$)          and         no\_overlap-10-35-3 ($35^{10}  \simeq   2.75\times  10^{15}$  configurations).    We then approximate the Hamming cost of each non-solution,  considering the closest solution among the 10,000 sampled solutions.
>>>>>>> d8966d39d92aa3a4fdceebf3697c7e881eb6830f

\begin{table}
  \centering
\begin{tabular}{|c|c|c|c|c|}
  \hline
  all\_diff & ord & lin\_sum & no\_ol & min\\
  \hline
  0 & 1.274 & 0.001 & 2.686 & 0\\
  \hline
\end{tabular}
\caption{Mean error  over 20,000 configurations in  high dimensions of
  learned cost functions over small complete constraint spaces.}
\label{tab:cf_scale}
\end{table}

Table\ref{tab:cf_scale} ...

\subsubsection{Experiment 2}

\subsubsection{Experiment 3}
\flo:  dire que  le but  ici  n'est pas  de  casser du  bench mais  de
comparer, même avec un solver  pas optimisé, les temps de résolutions
sans \cf, avec \cf apprise et avec \cf maison.

\section{Discussions}

Résultats améliorables  (notamment en  terme de  stabilité d'obtention
d'une CF optimale) en optimisant le GA, ce que nous n'avons pas fait.

Avantage  de  notre  modèle  :  les  CF  trouvées  sont  intelligibles
(contrairement aux NN). On peut même les coder en dur si l'on préfère,
plutôt que de calculer la CF avec un run forward du CPPN.

Peut être utilisé pour de l'aide à la décision, cad aider à définir un
CF à la main.

Autre avantage  : les CF  apprises sont robustes car  indépendantes de
l'instance des contraintes (taille et valeurs des paramètres)

La  simplification CPPN  où  les  poids sont  booléens  est aussi  une
avantage  pour  simplifier  la représentation  (et  compréhension,  et
reproduction) de la CF par rapport à des poids dans [0,1].

CPPN facile  à modifier (ses  opérations, notamment) pour  des besoins
spécifiques, des problèmes ou des contraintes particulières.


\section{Conclusion and perspectives}\label{sec:conclusion}

Faire du  RL plutôt  que du  SL. Pas  sûr que  Hamming soit  une bonne
métrique. Cela permettra de trouver des CF mieux adaptées aux algos.


\bibliographystyle{named}
\bibliography{main}

\end{document}
