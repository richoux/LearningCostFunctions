\documentclass[a4paper, 12pt]{article}

\usepackage[english]{babel}
\usepackage[T1]{fontenc} 
\usepackage[utf8]{inputenc}
\usepackage{fullpage}
\usepackage{url}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{graphicx} 
\usepackage{eurosym}
\usepackage{amsmath}
\usepackage{fourier}
\usepackage[normalem]{ulem}
\usepackage{pifont}
\usepackage{xcolor}

\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = blue %Colour of citations
}

\newcommand{\cmark}{\textcolor{green!80!black}{\ding{51}}}
\newcommand{\xmark}{\textcolor{red}{\ding{55}}}

\title{Draft v1 - Learning Cost Functions}
%\author{}
\date{\today}
 
\begin{document}
\maketitle

\includegraphics[width=\linewidth,angle=180]{20190529_whiteboard}

\section{Current method}
We  aim  to  learn  for  each  constraint  (type?)   a  cost  function
$f(\vec{x}) = c(\vec{x}).g(\vec{x})$, with $c(\vec{x})$ the constraint
concept defined by the user. We must then learn $g$.

Let's  defined $g$  to  be a  linear combination  of  sine and  cosine
functions such that:
\begin{displaymath}
g(\vec{x}) := \sum_{k=0}^{p}\big(a_k * cos(\vec{x}.2\pi.k) + b_k * sin(\vec{x}.2\pi.k)\big)
\end{displaymath}
Learning $g$ means learning coefficients $a_i, b_i$.
\begin{enumerate}
\item Using a genetic algorithm, start with a population of 100 random
  individuals. An  individual is the  vector $(a_0, b_0,  \ldots, a_p,
  b_p)$. Those coefficient are assigned to random values from a normal
  distribution of mean 0 and standard deviation $\sqrt n$, with $n$
  the number of variables of the target constraint.
\item  Current  parameters:   2000  generations,  crossover  rate=0.8,
  mutation rate=0.5.  
\item The  fitness function is  to maximize the  empirical correlation
  length multiplied by  the mean of $f$ on samples  from a random walk
  such that $f(\vec{x}) \neq 0$.
\end{enumerate}

This fitness function needs to  some further explanations. The idea is
to get a function  $f$ with a low ruggedness (in  other word, a smooth
function) such that its value concerning non-solutions is high.

The ruggedness of  a landscape can be computed by  doing a random walk
from  a random  configuration, and  compute the  empirical correlation
length $l$ (see \cite{Hoos2005}, Chapter 5). To do so, we need first to define the
empirical autocorrelation function $r(i)$.
\begin{displaymath}
r(i)               :=\frac{\frac{1}{(m-i)}\cdot\sum\limits_{k=1}^{m-i}\left(f_{k}-\overline{f}\right)
  \cdot\left(f_{k+i}-\overline{f}\right)}{\frac{1}{m}\cdot\sum\limits_{k=1}^{m}\left(f_{k}-\overline{f}\right)^{2}}
\end{displaymath}
with $m$ the length of the random  walk, $f_k$ the value of $f$ on the
$k$-th configuration of  the random walk, and  $\overline{f}$ the mean
of those $f_k$.

We can then compute the empirical correlation length $l$ such that
\begin{displaymath}
l := \frac{1}{ln(|r(1)|)}
\end{displaymath}

Intuitively, the higher the value $l$, the smoother the function $f$.

However, we  need to avoid  learning a flat function  projecting every
configuration  to the  value  0  (it would  be  super-smooth but  also
super-useless for  the solver). To  avoid this situation,  the fitness
function of the genetic algorithm is to maximize $l$ times the mean of
$f$ over configurations in the random walk that are not solutions (ie,
$f(\vec{x}) \neq  0$). Thus,  the algorithm will  try to  learn smooth
functions that severely penalize non-solution configurations.

\subsection{Main advantages of the method}



\section{Main ideas}
\begin{enumerate}
\item The user must first provide for each constraint type a function $b(\vec{x}) = \left\{
  \begin{array}{rl}
    0 & \text{if } x \text{ is a solution}\\
    1 & y\text{otherwise}
  \end{array} \right.$
$b$ is called ``concept'' in some papers.
\item The goal is to learn $f(\vec x)$ such that the cost function is defined by $b(\vec x) . f(\vec x)$.

\item Find a metric $|.|_l$ in the constraint configuration space. (\danger Space liked to the constraint, since depending one the variables and their domains.)
\item Project the current configuration $\vec{x}$ on the closest solution $\vec{s}$, giving $f(\vec x) = |\vec{s}-\vec{x}|_l$. Need to search for this closest $\vec{s}$ (n-dimensional Vorono√Ø cells?).
\item Fourier transform of the cost function $f'$ of a well-known constraint like all-diff or equality to compare 'hand-designed' harmonics and learned ones.
\item Possible metrics:
  \begin{itemize}
  \item Manhattan: $\sum\limits_i |s[i] - x[i]|$
  \item Hamming: number of variables to change to get a solution (ideal for local search)
  \item Number of swaps of values to get a solution (ideal for permutation constraints).
  \item Manhattan/Hamming mix: Hamming first, then Manhattan as a tie-breaker.
  \end{itemize}
\item Brute-force solution search on small spaces: from a configuration $\vec{x}$, try all possible combinations and test if it is a solution. Early-stop: once we have found a solution, no need to continue the search.
\item The idea is to characterize the cost functions over small instances (few variables/small domains) to make it scale over larger instances.
\item Multivariate  interpolation to find  a scalable formula  for $f$
  (\sout{chebpol} splinter).
\item  Use  of   Genetic  Algorithms/Programming,  other  Evolutionary
  Computation,    Reinforcement    learning,   Supervised    learning?
  $\Rightarrow$ iterative building of cost functions.
\end{enumerate}

\section{Sidekick ideas}
\begin{itemize}
\item[1 bis] The user provides some examples $\vec{x}$ 1. near to be a solution, 2. not a solution but not ridiculous and 3. being a really bad configuration.
\item[3 bis] Could be simplified by a linear transform contracting the constraint configuration space on the manyfold of solutions (so det = 0). Only possible if the manyfold is linear?
\item[5 bis] Random draw of solutions to estimate a projection. Need to know and save solutions somewhere (or to be able to find them quickly).
\item   [6    bis]   See   also   Kantorovich    functional   distance
  from~\cite{StochCP}. See also~\cite{metrics}.
\item [7 bis] Random samplings of the configuration space:
  \begin{enumerate}
  \item Draw a configuration.
  \item Scan all neighbors (with simple '1 variable' neighborhood), or
    sample neighbors (this can be parallelized).
  \item Cost  = numbers of or  mean of neighbors with  a cost strictly
    lesser. Problem: what  are those costs? We are trying  to build it
    actually. Only for iterative processes?
  \end{enumerate}
\item [8 bis] Generate training examples and do reinforcement learning/supervised learning (regression problem)? keeping in mind we look for a function based over the sum of harmonics.
\end{itemize}

\section{Processing data}
\begin{itemize}
\item Normalize samples or apply  a $log_2(x+2)-1$ scaling function to
  diminish potential gaps, in particular  when we have solutions (cost
  = 0).
\item Idea of backward JLL or ``kind of kernel trick'':
  \begin{enumerate}
  \item The user furnishes constraint concepts.
  \item We apply JLL to reduce the space size.
  \item We learn our cost function on this space.
  \item  We apply  some  ``backward  JLL'' to  this  cost function  to
    preserve its properties on the original space.
  \end{enumerate}
\end{itemize}

\section{Formalization}
Define WCSP and CFN such that:
\begin{itemize}
\item  WCSP is  considering soft  constraints, where  a constraint  is
  unsatisfyed iif its associated cost function outputs a value below a
  given threshold $k$ (can be infinite).
\item  CFN  is  considering  hard constraints  only.  Like  constraint
  networks helping solvers to find  solutions by giving a structure of
  the problem,  CFN gives,  in addition of  the constraint  network, a
  structure on  configurations to help  the solver to determine  if an
  unsatisfying configuration is near to be a solution or not.
\item Expressiveness: CFN-sat $<$ WCSP $<$ CFN-opt
\item Reductions/transformation: WCSP $\Rightarrow$ CFN-opt
\end{itemize}

\section{Scaling-related problems}
Several ways to handle scaling.
\begin{enumerate}
\item Learn a function on a small  space and expend it to the original
  space.
\item Draw some samples from the original space
\item Detect and apply symmetries in the original space.
\item Apply JLL to reduce to  original space. maps solutions from this
  space to the compact one, and compute a metric on that compact space
  (eventually learn a function on it).
\end{enumerate}

Problems with those methods so far:
\begin{enumerate}
\item We have no idea how to extend functions with higher cardinality
\item Draw  some samples  does not work  well for  interpolation (10\%
  does not give good results)
\item It is hard to detect AND to correctly apply symmetries.
\item Maybe the solution.
\end{enumerate}

Bonus: what is the point to learn a function if we cannot extend it to
higher spaces?  Computing a  metric on  all points  (or being  able to
compute it on-the-fly quickly) is sufficient.

Furthermore,  a method  based on  scanning solutions  of the  original
configuration space is  not tractable: there is NO  way to efficiently
compute those  solutions, otherwise  complete algorithms would  not do
search but would  rather tried to combined  constraints' solutions. We
have to find another way.

\subsection{Build solutions incrementally}
If $(x_1,  \ldots, x_{k-1})$  is a  solution, then  try all  values of
$x_k$       with       $(x_k,      x_1,       \ldots,       x_{k-1})$,
$(x_1,         x_k,        \ldots,         x_{k-1})$,        $\ldots$,
$(x_1, \ldots, x_{k-1},  x_k)$. It does not work  with all constraints
(constraint 'sum =  constant' for instance), so with which  ones it is
OK? Being incremental  here means only solutions  on $k-1$ variables
can lead to solutions on $k$ variables.

Classic global constraints in XCSP3-core:
\begin{itemize}
\item regular: \cmark
\item mdd: more a representation than a constraint.
\item allDifferent: \cmark
\item allEqual: \cmark
\item ordered (lessThan extension): \cmark
\item sum: \xmark
\item count: \xmark
\item nValues: \xmark
\item cardinality: \xmark
\item minimum: \xmark
\item maximum: \xmark
\item element: \cmark~for the index version, \xmark~for the membership-only version.
\item channel:  \cmark~but only  adding a variable at  the end
  can lead to solutions.
\item stretch: ???
\item noOverlap: \cmark
\item cumulative: \xmark
\end{itemize}

\section{To explore}
\begin{itemize}
\item Can the Johnson-Lindenstrauss Lemma be useful here?
\item Dichotomy (!?)
\item Constraint classification regarding their cost function.
\item Compute the cost function of the main global constraints.
\item Study the robustness of the cost function regarding the ratio $\frac{|Domain|}{\# vars}$. Does normalization change something?
\item   Compositional  pattern-producing   network  (CPPN~\cite{CPPN})
  instead of the sum of harmonics.
\item For iterative  building (or maybe not):  symmetries detection (=
  free  samples,  see  2.7bis)  should  make  cost  function  building
  faster/easier.
\item Decomposing  complex context  functions given  by the  user into
  some simple functions.
\end{itemize}

\section{Questions / issues}
\begin{itemize}
\item Discrete case of trigonometric functions.
\item How to scale over more variables, like $\text{all-diff}(x, y, z)
  \rightarrow \text{all-diff}(x_1, \ldots, x_n)$
\item How to display an interpoled function on chebpol?
\item Metrics  over the function  space, to  see if two  functions are
  similar or not:
  \begin{itemize}
  \item interpoled function over the  full search space vs. interpoled
    function over samples
  \item interpoled function vs. hand-designed function.
  \end{itemize}
\item Examples of constraints with local minimum? (good to know for cost function iterative building)
\end{itemize}


\bibliographystyle{alpha}
\bibliography{draft}

\end{document}
